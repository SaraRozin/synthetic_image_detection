{"cells":[{"cell_type":"code","execution_count":null,"id":"e1dd0344","metadata":{"id":"e1dd0344"},"outputs":[],"source":["import torch\n","%run data_dif.ipynb\n","%run trainer_dif.ipynb\n","%run utils.ipynb\n","import pickle\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"id":"64cc9d37","metadata":{"id":"64cc9d37"},"outputs":[],"source":["class DetectGenerativeModel:\n","    self.fingerprints = None\n","    self.generative_models = None"]},{"cell_type":"code","execution_count":null,"id":"14cc4212","metadata":{"id":"14cc4212"},"outputs":[],"source":["class GenerativeModel(TrainerMultiple):\n","    def __init__(self, fingerprint_dir, image_dir, epoch=0, batch=64):\n","        model_ep = epoch\n","        images_dir = Path(image_dir)\n","        check_dir = Path(fingerprint_dir)\n","        check_existence(check_dir, False)\n","        check_existence(images_dir, False)\n","        with open(check_dir / \"train_hypers.pt\", 'rb') as pickle_file:\n","            hyperparams = pickle.load(pickle_file)\n","        hyperparams['Device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        hyperparams['Batch Size'] = batch\n","        super().__init__(hyperparams)\n","\n","    def get_correlation(self, img_path):\n","        image = load_pil_image(img_path, self.crop_size)\n","        image = np.array(image)\n","        image = torch.tensor(image.transpose((2, 0, 1))).type(torch.float32).div(255)\n","        residuals = self.denoiser.denoise([image]).detach()\n","        alpha = (1 - self.alpha) * torch.rand((len(images), 1, 1, 1)).to(self.device) + self.alpha\n","        residuals = alpha * residuals\n","        residuals = torch.cat((residuals, f_mean, r_mean), dim=0)\n","        corr = self.corr_fun(self.fingerprint, residuals)\n","        return corr[0]\n","\n","a = GenerativeModel(fingerprint_dir=0, batch=50)\n","isintance(a, image)\n","# def __instancecheck__(self, img_path):\n"]},{"cell_type":"code","execution_count":null,"id":"0a9256d4","metadata":{"id":"0a9256d4"},"outputs":[],"source":["def load_pil_image(img_path, img_size=None):\n","    img = Image.open(img_path).convert('RGB')\n","\n","    if img_size is not None:\n","        w, h = img.size\n","        left = (w - img_size[1]) / 2\n","        top = (h - img_size[0]) / 2\n","        right = (w + img_size[1]) / 2\n","        bottom = (h + img_size[0]) / 2\n","\n","        img = img.crop((left, top, right, bottom))\n","\n","    return img"]},{"cell_type":"code","execution_count":null,"id":"f0e478f1","metadata":{"id":"f0e478f1"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}